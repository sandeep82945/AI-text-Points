{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4503178-2988-4ef1-928c-fbb136f22fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b55c5a9-59ca-4f77-878c-3e3fdf28b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('responses_200_samples.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "human_sentences_true = []\n",
    "ai_sentences_true = []\n",
    "human_sentences_gen = []\n",
    "ai_sentences_gen = []\n",
    "count_gen_human = 0\n",
    "count_true_human = 0\n",
    "count_gen_ai = 0\n",
    "count_true_ai = 0\n",
    "\n",
    "error_paper_ids_human = []\n",
    "error_paper_ids_ai = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993e829b-9544-4b17-be30-b4fd6acbd479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error! No 2nd index found!:  ['Theoretical analysis is thorough, including some relatively non-intuitive results, e.g., Lemma 3.5 which shows that the expected number of null arm pulls is constant.'] lHy09zPewmD\n",
      "Error! No 2nd index found!:  ['I would say that overall, the technical advance is very incremental. For example, much of the same ideas are already used in survival analysis for estimating the monotonically decreasing survival probability function over time (e.g., Kvamme and Borgan 2021, although the same ideas in parameterizing the monotonic survival function appear in earlier papers, some of which are referenced within Kvamme and Borgan), where standard neural net training procedures suffice. One could perhaps argue that the novelty lies in the specific application to partially monotone regression and the hierarchical lattice structure.'] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  ['The key technical ideas are actually not that complicated although the hierarchical structure adds some complexity.'] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  ['The author(s) provide sufficient empirical evidence that the proposed hierarchical lattice layer (HLL) does not sacrifice prediction performance.'] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  ['I found the presentation at times to be more complicated than it needs to be. I would suggest adding a simple running example (could help clarify the hierarchical lattice structure and its benefits).'] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  ['It would be helpful relating the proposed method to possibly special cases of how people have previously enforced monotonicity without resorting to complex lattice structures.'] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  [\"Minor: Please appropriately switch between using 'citep' and 'citet' for references (currently, the paper basically uses the equivalent of 'citet' too often so that it disrupts the flow of the text).\"] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  [\"In line 19-20, I'd suggest you use 'citep' so that the citation is less intrusive.\"] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  [\"In lines 25-28, if you use 'citep', you would get: 'For example, they have a better regularization capability [Dugas et al., 2000; Fard et al., 2016; You et al., 2017].'\"] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  ['Kvamme H, Borgan Ã˜. Continuous and discrete-time survival models using neural networks.'] zAuiZpZ478l\n",
      "Error! No 2nd index found!:  ['This paper proposes a new programming model, which abstracts the search space as a probabilistic language and allows incorporation of domain knowledge, for tensor program optimization.'] nyCr6-0hinG\n",
      "Error! No 2nd index found!:  ['The results in the paper verifies the role of depth in interpolation and approximation of monotone neural networks.'] vQzDYi4dPwM\n",
      "Error! No 2nd index found!:  ['Compared to multi-agent reinforcement learning algorithms, the proposed algorithm in this paper offers a more structured approach to consensus-seeking agents.'] ufRSbXtgbOo\n",
      "Error! No 2nd index found!:  ['* This paper studies the behavior of SGD in SCO, providing new intuition of the analysis of test error (population risk). By their construction, even in the convex optimization, there exists an instance that provably minimizes population risk, while the empirical risk is of constant level, resulting in a constant generalization gap. This observation highlights a fundamental limitation of traditional generalization bounds, as they fail to explain the behavior of SGD in such cases.'] lCGDKJGHoUv\n",
      "Error! No 2nd index found!:  ['* The other observations, together with their proof techniques are also interesting. For example, the comparison between with-replacement and without-replacement SGD provides valuable insights into the differences in their generalization properties.'] lCGDKJGHoUv\n",
      "Error! No 2nd index found!:  ['* The paper is well-structured and clearly presents the theoretical contributions.'] lCGDKJGHoUv\n",
      "Error! No 2nd index found!:  ['* The construction of the failure seems artificial and might not be general enough. They rely on a special structure that (to my best knowledge) no practical machine learning problem exhibits, which limits the applicability of the results.'] lCGDKJGHoUv\n",
      "Error! No 2nd index found!:  ['* The analysis relies on the averaged solution instead of the last iteration solution, which prevents the general impact of this work from being fully realized in practical settings.'] lCGDKJGHoUv\n",
      "Error! No 2nd index found!:  ['The proposed method is novel to me and leverages recent advances made on the SPD manifold such as the Gaussian distribution, the geometric law of large numbers.'] pp7onaiM4VB\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "for paper_id in data:\n",
    "    for reviewer in data[paper_id]:\n",
    "        human_generated_review = ast.literal_eval(data[paper_id][reviewer]['human_strength_and_weaknesses']['1']['sentence'])\n",
    "                \n",
    "        for lst in human_generated_review['review']:\n",
    "            if len(lst) > 1:\n",
    "                count_gen_human += 1\n",
    "                human_sentences_gen.append(lst[1])\n",
    "            else:\n",
    "                print(\"Error! No 2nd index found!: \", lst, paper_id)\n",
    "                error_paper_ids_human.append(paper_id)\n",
    "        gt_sentences = data[paper_id][reviewer]['human_strength_and_weaknesses']['1']['gt_sentence']\n",
    "        for gt in gt_sentences:\n",
    "            count_true_human += 1\n",
    "            human_sentences_true.append(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2ec39e-9cee-4065-97e6-a4d0f5416fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of true human sentences: 1279, No. of generated human sentences: 1376\n"
     ]
    }
   ],
   "source": [
    "print(f\"No. of true human sentences: {len(human_sentences_true)}, No. of generated human sentences: {len(human_sentences_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72192e02-5fcb-4fe5-a2ff-3a87dbaf375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper IDs with error (improper list-match): {'lCGDKJGHoUv', 'ufRSbXtgbOo', 'pp7onaiM4VB', 'vQzDYi4dPwM', 'nyCr6-0hinG', 'zAuiZpZ478l', 'lHy09zPewmD'}\n"
     ]
    }
   ],
   "source": [
    "error_paper_ids_human = set(error_paper_ids_human)\n",
    "print(\"Paper IDs with error (improper list-match):\", error_paper_ids_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d9734d4-d7d2-4d3b-91d1-f6c99aaaa20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_sentences_true = []\n",
    "human_sentences_gen = []\n",
    "count_gen_human = 0\n",
    "count_true_human = 0\n",
    "unequal_gen_vs_true_human = []\n",
    "\n",
    "for paper_id in data:\n",
    "    if paper_id in error_paper_ids_human:\n",
    "        continue\n",
    "    for reviewer in data[paper_id]:\n",
    "        current_human_true = []\n",
    "        current_human_gen = []\n",
    "        human_generated_review = ast.literal_eval(data[paper_id][reviewer]['human_strength_and_weaknesses']['1']['sentence'])\n",
    "                \n",
    "        for lst in human_generated_review['review']:\n",
    "            if len(lst) > 1:\n",
    "                count_gen_human += 1\n",
    "                current_human_gen.append(lst[1])\n",
    "            else:\n",
    "                print(\"Error! No 2nd index found!: \", lst, paper_id)\n",
    "                error_paper_ids_human.append(paper_id)\n",
    "        gt_sentences = data[paper_id][reviewer]['human_strength_and_weaknesses']['1']['gt_sentence']\n",
    "        for gt in gt_sentences:\n",
    "            count_true_human += 1\n",
    "            current_human_true.append(gt)\n",
    "        if len(current_human_true) == len(current_human_gen):\n",
    "            human_sentences_true.extend(current_human_true)\n",
    "            human_sentences_gen.extend(current_human_gen)\n",
    "        else:\n",
    "            unequal_gen_vs_true_human.append(paper_id)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123c0c4a-a6b8-48cc-a1c7-5d02c0a46d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of true human sentences after filtering: 1033, No. of generated human sentences after filtering: 1033\n"
     ]
    }
   ],
   "source": [
    "print(f\"No. of true human sentences after filtering: {len(human_sentences_true)}, No. of generated human sentences after filtering: {len(human_sentences_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4b6f93-ca2d-4a00-8843-9cc38c735ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 Paper IDs that had unequal matches for generated vs gt: ['x8DNliTBSYY', 'uFSrUpapQ5K', 'pfI7u0eJAIr', 'rA2tItoRUth', 'nyn2ewuF-g9', 'mUeMOdJ2IJp', 't0VbBTw-o8', 'qfC1uDXfDJo', 'xNeAhc2CNAl', 'weoLjoYFvXY', 'znbTxnBPlx', 's71h4wo9bFI', 'sjaQ2bHpELV', 'lXuZaxEaI7', 'l1WlfNaRkKw', 'tIZtD2kZ6zx', 'w1CF57sLstO', 'w-Aq4vmnTOP', 'ripJhpwlA2v', 'nxl-IjnDCRo', 'xbJAITw9Z6t', 'mMdRZipvld2', 'wUUutywJY6', 'sPNtVVUq7wi', 'wxWTyJtiJZ', 'qm5LpHyyOUO', 'krV1UM7Uw1', 'wwyiEyK-G5D', 'u3vEuRr08MT', 'lWq3KDEIXIE', 'vjKIKdXijK', 'sn6BZR4WvUR', 'wOI0AUAq9BR', 'w0O3F4cTNfG', 'zrAUoI2JA2', 'tIqzLFf3kk', 'sQ2LdeHNMej', 'nJt27NQffr', 'ldxUm0mmhl8']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(unequal_gen_vs_true_human)} Paper IDs that had unequal matches for generated vs gt:\", unequal_gen_vs_true_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6efc6bb-cbc6-4608-afac-e2a81053ef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error! No 2nd index found!:  ['The paper is well-structured, providing clear explanations of the problem and the proposed solution.'] s776AhRFm67\n",
      "Error! No 2nd index found!:  ['The theoretical framework is rigorous and provides insights into the relationship between barely robust and strongly robust learning.'] s776AhRFm67\n",
      "Error! No 2nd index found!:  ['The experiments conducted on synthetic and MNIST datasets demonstrate the effectiveness of the proposed boosting algorithm.'] s776AhRFm67\n",
      "Error! No 2nd index found!:  ['The paper addresses important questions in adversarial robustness and contributes to the understanding of boosting techniques in this domain.'] s776AhRFm67\n",
      "Error! No 2nd index found!:  ['The complexity of the algorithms and theoretical concepts might make it challenging for practitioners to implement without further simplifications.'] s776AhRFm67\n",
      "Error! No 2nd index found!:  ['The paper primarily focuses on the realizable setting, and it would be interesting to explore extensions to the agnostic setting.'] s776AhRFm67\n",
      "Error! No 2nd index found!:  ['The experiments are limited to linear SVM as a baseline barely robust learner, and it would be beneficial to test the approach on more complex models.'] s776AhRFm67\n",
      "Error! No 2nd index found!:  ['The paper provides a clear and well-structured description of Lewis signaling games, the motivation behind their use in modeling language emergence.'] qqHMvHbfu6\n",
      "Error! No 2nd index found!:  ['The decomposition of the loss function into information and co-adaptation losses is insightful and well-explained.'] qqHMvHbfu6\n",
      "Error! No 2nd index found!:  ['The experimental results effectively demonstrate the impact of controlling the co-adaptation loss on generalization.'] qqHMvHbfu6\n",
      "Error! No 2nd index found!:  ['The authors provide thorough discussions on the implications of their findings for language emergence models.'] qqHMvHbfu6\n",
      "Error! No 2nd index found!:  ['While the paper presents clear experimental results, additional baselines could strengthen the conclusions.'] qqHMvHbfu6\n",
      "Error! No 2nd index found!:  ['The paper could benefit from a more detailed discussion on the limitations of the proposed framework.'] qqHMvHbfu6\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "ai_sentences_true = []\n",
    "ai_sentences_gen = []\n",
    "count_gen_ai = 0\n",
    "count_true_ai = 0\n",
    "\n",
    "for paper_id in data:\n",
    "    for reviewer in data[paper_id]:\n",
    "        ai_generated_review = ast.literal_eval(data[paper_id][reviewer]['ai_strength_and_weaknesses']['1']['sentence'])\n",
    "                \n",
    "        for lst in ai_generated_review['review']:\n",
    "            if len(lst) > 1:\n",
    "                count_gen_ai += 1\n",
    "                ai_sentences_gen.append(lst[1])\n",
    "            else:\n",
    "                print(\"Error! No 2nd index found!: \", lst, paper_id)\n",
    "                error_paper_ids_ai.append(paper_id)\n",
    "        \n",
    "        gt_sentences = data[paper_id][reviewer]['ai_strength_and_weaknesses']['1']['gt_sentence']\n",
    "        for gt in gt_sentences:\n",
    "            count_true_ai += 1\n",
    "            ai_sentences_true.append(gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0e9e8e-7fba-4f95-b808-b5c685a09013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of true ai sentences: 1339, No. of generated ai sentences: 1327\n"
     ]
    }
   ],
   "source": [
    "print(f\"No. of true ai sentences: {len(ai_sentences_true)}, No. of generated ai sentences: {len(ai_sentences_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef13f4a9-551b-4013-b42b-df9543c294b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper IDs with error (improper list-match for AI): {'qqHMvHbfu6', 's776AhRFm67'}\n"
     ]
    }
   ],
   "source": [
    "error_paper_ids_ai = set(error_paper_ids_ai)\n",
    "print(\"Paper IDs with error (improper list-match for AI):\", error_paper_ids_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09eb1fbd-f0fb-486d-bfc8-02c4c6da1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_sentences_true = []\n",
    "ai_sentences_gen = []\n",
    "count_gen_ai = 0\n",
    "count_true_ai = 0\n",
    "unequal_gen_vs_true_ai = []\n",
    "\n",
    "for paper_id in data:\n",
    "    if paper_id in error_paper_ids_ai:\n",
    "        continue\n",
    "    for reviewer in data[paper_id]:\n",
    "        current_ai_true = []\n",
    "        current_ai_gen = []\n",
    "        ai_generated_review = ast.literal_eval(data[paper_id][reviewer]['ai_strength_and_weaknesses']['1']['sentence'])\n",
    "                \n",
    "        for lst in ai_generated_review['review']:\n",
    "            if len(lst) > 1:\n",
    "                count_gen_ai += 1\n",
    "                current_ai_gen.append(lst[1])\n",
    "            else:\n",
    "                print(\"Error! No 2nd index found!: \", lst, paper_id)\n",
    "                error_paper_ids_ai.append(paper_id)\n",
    "                \n",
    "        gt_sentences = data[paper_id][reviewer]['ai_strength_and_weaknesses']['1']['gt_sentence']\n",
    "        for gt in gt_sentences:\n",
    "            count_true_ai += 1\n",
    "            current_ai_true.append(gt)\n",
    "            \n",
    "        if len(current_ai_true) == len(current_ai_gen):\n",
    "            ai_sentences_true.extend(current_ai_true)\n",
    "            ai_sentences_gen.extend(current_ai_gen)\n",
    "        else:\n",
    "            unequal_gen_vs_true_ai.append(paper_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d163a4e-2f48-4383-becf-ae0b603f436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of true AI sentences after filtering: 1319, No. of generated AI sentences after filtering: 1319\n"
     ]
    }
   ],
   "source": [
    "print(f\"No. of true AI sentences after filtering: {len(ai_sentences_true)}, No. of generated AI sentences after filtering: {len(ai_sentences_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f8bb9e-7153-4c89-80f7-58afec1c4e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Paper IDs that had unequal matches for generated vs gt: ['qm5LpHyyOUO', 'qSs7C7c4G8D']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(unequal_gen_vs_true_ai)} Paper IDs that had unequal matches for generated vs gt:\", unequal_gen_vs_true_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7a57e01-eb02-490f-aef7-251a4ea2475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human = pd.DataFrame({\n",
    "    'True Sentences': human_sentences_true,\n",
    "    'Generated Sentences': human_sentences_gen\n",
    "})\n",
    "\n",
    "df_ai = pd.DataFrame({\n",
    "    'True Sentences': ai_sentences_true,\n",
    "    'Generated Sentences': ai_sentences_gen\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6052fbef-25ff-4005-bdc1-6b6ff158a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human.to_csv('human_sentences.csv', index=False)\n",
    "df_ai.to_csv('ai_sentences.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
